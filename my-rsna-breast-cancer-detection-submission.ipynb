{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066b1e5d",
   "metadata": {
    "papermill": {
     "duration": 0.006364,
     "end_time": "2023-02-07T21:49:20.370262",
     "exception": false,
     "start_time": "2023-02-07T21:49:20.363898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This is based on the notebook by Radek [here](https://www.kaggle.com/code/radek1/fast-ai-starter-pack-train-inference)\n",
    "\n",
    "* Planning to create a seperate training notebook to experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cca966",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T00:49:16.208915Z",
     "iopub.status.busy": "2022-12-02T00:49:16.208242Z",
     "iopub.status.idle": "2022-12-02T00:49:16.247884Z",
     "shell.execute_reply": "2022-12-02T00:49:16.244677Z",
     "shell.execute_reply.started": "2022-12-02T00:49:16.20876Z"
    },
    "papermill": {
     "duration": 0.004394,
     "end_time": "2023-02-07T21:49:20.379650",
     "exception": false,
     "start_time": "2023-02-07T21:49:20.375256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-one\"></a>\n",
    "# Training a fast.ai model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9789412c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:49:20.391619Z",
     "iopub.status.busy": "2023-02-07T21:49:20.390462Z",
     "iopub.status.idle": "2023-02-07T21:50:35.431844Z",
     "shell.execute_reply": "2023-02-07T21:50:35.430724Z"
    },
    "papermill": {
     "duration": 75.050293,
     "end_time": "2023-02-07T21:50:35.434729",
     "exception": false,
     "start_time": "2023-02-07T21:49:20.384436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: timm-with-dependencies\r\n",
      "Processing ./timm-with-dependencies/timm-0.6.12-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.7.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.13.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.64.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.9.24)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.6.12\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "Installing collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Remove timm foder otherwise it takes a while to run or you have to cancel run\n",
    "import shutil\n",
    "#shutil.rmtree('/kaggle/working/timm-with-dependencies')\n",
    "\n",
    "!unzip -q ../input/timm-with-dependencies/timm_all -d timm-with-dependencies\n",
    "!pip install --no-index --find-links timm-with-dependencies timm\n",
    "!pip install /kaggle/input/dicomsdl-offline-installer/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "\n",
    "from fastai.vision.learner import *\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.metrics import ActivationType\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454a8678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:50:35.447913Z",
     "iopub.status.busy": "2023-02-07T21:50:35.446887Z",
     "iopub.status.idle": "2023-02-07T21:50:38.224235Z",
     "shell.execute_reply": "2023-02-07T21:50:38.223270Z"
    },
    "papermill": {
     "duration": 2.78638,
     "end_time": "2023-02-07T21:50:38.226634",
     "exception": false,
     "start_time": "2023-02-07T21:50:35.440254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 4\n",
    "NUM_SPLITS = 4\n",
    "\n",
    "RESIZE_TO = (1024, 1024)\n",
    "\n",
    "DATA_PATH = '/kaggle/input/rsna-breast-cancer-detection'\n",
    "TRAIN_IMAGE_DIR = '/kaggle/input/rsna-mammography-images-as-pngs/images_as_pngs_cv2_512'\n",
    "TEST_DICOM_DIR = '/kaggle/input/rsna-breast-cancer-detection/test_images'\n",
    "MODEL_PATH = '/kaggle/input/rsna-trained-model-weights/tf_effv2_s_208_402/tf_effv2_s_208_402'\n",
    "\n",
    "label_smoothing_weights = torch.tensor([1,10]).float()\n",
    "if torch.cuda.is_available():\n",
    "    label_smoothing_weights = label_smoothing_weights.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b4779",
   "metadata": {
    "papermill": {
     "duration": 0.005199,
     "end_time": "2023-02-07T21:50:38.237365",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.232166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating stratified splits for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c660c262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:50:38.249100Z",
     "iopub.status.busy": "2023-02-07T21:50:38.248777Z",
     "iopub.status.idle": "2023-02-07T21:50:38.366168Z",
     "shell.execute_reply": "2023-02-07T21:50:38.365223Z"
    },
    "papermill": {
     "duration": 0.126399,
     "end_time": "2023-02-07T21:50:38.368948",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.242549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "patient_id_any_cancer = train_csv.groupby('patient_id').cancer.max().reset_index()\n",
    "skf = StratifiedKFold(NUM_SPLITS, shuffle=True, random_state=42)\n",
    "splits = list(skf.split(patient_id_any_cancer.patient_id, patient_id_any_cancer.cancer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693678e8",
   "metadata": {
    "papermill": {
     "duration": 0.005316,
     "end_time": "2023-02-07T21:50:38.381246",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.375930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e49296",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-02-07T21:50:38.393535Z",
     "iopub.status.busy": "2023-02-07T21:50:38.393187Z",
     "iopub.status.idle": "2023-02-07T21:50:38.457112Z",
     "shell.execute_reply": "2023-02-07T21:50:38.455984Z"
    },
    "papermill": {
     "duration": 0.072689,
     "end_time": "2023-02-07T21:50:38.459341",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.386652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/369267  \n",
    "def pfbeta_torch(preds, labels, beta=1):\n",
    "    if preds.dim() != 2 or (preds.dim() == 2 and preds.shape[1] !=2): raise ValueError('Houston, we got a problem')\n",
    "    preds = preds[:, 1]\n",
    "    preds = preds.clip(0, 1)\n",
    "    y_true_count = labels.sum()\n",
    "    ctp = preds[labels==1].sum()\n",
    "    cfp = preds[labels==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/369886    \n",
    "def pfbeta_torch_thresh(preds, labels):\n",
    "    optimized_preds = optimize_preds(preds, labels)\n",
    "    return pfbeta_torch(optimized_preds, labels)\n",
    "\n",
    "def optimize_preds(preds, labels=None, thresh=None, return_thresh=False, print_results=False):\n",
    "    preds = preds.clone()\n",
    "    if labels is not None: without_thresh = pfbeta_torch(preds, labels)\n",
    "    \n",
    "    if not thresh and labels is not None:\n",
    "        threshs = np.linspace(0, 1, 101)\n",
    "        f1s = [pfbeta_torch((preds > thr).float(), labels) for thr in threshs]\n",
    "        idx = np.argmax(f1s)\n",
    "        thresh, best_pfbeta = threshs[idx], f1s[idx]\n",
    "\n",
    "    preds = (preds > thresh).float()\n",
    "\n",
    "    if print_results:\n",
    "        print(f'without optimization: {without_thresh}')\n",
    "        pfbeta = pfbeta_torch(preds, labels)\n",
    "        print(f'with optimization: {pfbeta}')\n",
    "        print(f'best_thresh = {thresh}')\n",
    "    if return_thresh:\n",
    "        return thresh\n",
    "    return preds\n",
    "\n",
    "fn2label = {fn: cancer_or_not for fn, cancer_or_not in zip(train_csv['image_id'].astype('str'), train_csv['cancer'])}\n",
    "\n",
    "def splitting_func(paths):\n",
    "    train = []\n",
    "    valid = []\n",
    "    for idx, path in enumerate(paths):\n",
    "        if int(path.parent.name) in patient_id_any_cancer.iloc[splits[SPLIT][0]].patient_id.values:\n",
    "            train.append(idx)\n",
    "        else:\n",
    "            valid.append(idx)\n",
    "    return train, valid\n",
    "\n",
    "def label_func(path):\n",
    "    return fn2label[path.stem]\n",
    "\n",
    "def get_items(image_dir_path):\n",
    "    items = []\n",
    "    for p in get_image_files(image_dir_path):\n",
    "        items.append(p)\n",
    "        if p.stem in fn2label and int(p.parent.name) in patient_id_any_cancer.iloc[splits[SPLIT][0]].patient_id.values:\n",
    "            if label_func(p) == 1:\n",
    "                for _ in range(5):\n",
    "                    items.append(p)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07158675",
   "metadata": {
    "papermill": {
     "duration": 0.005394,
     "end_time": "2023-02-07T21:50:38.470214",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.464820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wrapping getting data and getting a model into functions -- this way our logic for training will be cleaner to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c880311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:50:38.482011Z",
     "iopub.status.busy": "2023-02-07T21:50:38.481684Z",
     "iopub.status.idle": "2023-02-07T21:50:38.489809Z",
     "shell.execute_reply": "2023-02-07T21:50:38.488774Z"
    },
    "papermill": {
     "duration": 0.01656,
     "end_time": "2023-02-07T21:50:38.492064",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.475504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timm.models.layers.adaptive_avgmax_pool import SelectAdaptivePool2d\n",
    "from torch.nn import Flatten\n",
    "\n",
    "def get_dataloaders():\n",
    "    train_image_path = TRAIN_IMAGE_DIR\n",
    "\n",
    "    dblock = DataBlock(\n",
    "        blocks    = (ImageBlock, CategoryBlock),\n",
    "        get_items = get_items,\n",
    "        get_y = label_func,\n",
    "        splitter  = splitting_func,\n",
    "        batch_tfms=[Flip()],\n",
    "    )\n",
    "    dsets = dblock.datasets(train_image_path)\n",
    "    return dblock.dataloaders(train_image_path, batch_size=32)\n",
    "\n",
    "def get_learner(arch=resnet18):\n",
    "    learner = vision_learner(\n",
    "        get_dataloaders(),\n",
    "        arch,\n",
    "        custom_head=nn.Sequential(SelectAdaptivePool2d(pool_type='avg', flatten=Flatten()), nn.Linear(1280, 2)),\n",
    "        metrics=[\n",
    "            error_rate,\n",
    "            AccumMetric(pfbeta_torch, activation=ActivationType.Softmax, flatten=False),\n",
    "            AccumMetric(pfbeta_torch_thresh, activation=ActivationType.Softmax, flatten=False)\n",
    "        ],\n",
    "        loss_func=CrossEntropyLossFlat(weight=torch.tensor([1,50]).float()),\n",
    "        pretrained=True,\n",
    "        normalize=False\n",
    "    ).to_fp16()\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5b471",
   "metadata": {
    "papermill": {
     "duration": 0.004968,
     "end_time": "2023-02-07T21:50:38.502190",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.497222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating the learner and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97726c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:50:38.514328Z",
     "iopub.status.busy": "2023-02-07T21:50:38.513441Z",
     "iopub.status.idle": "2023-02-07T21:52:26.332831Z",
     "shell.execute_reply": "2023-02-07T21:52:26.331510Z"
    },
    "papermill": {
     "duration": 107.828196,
     "end_time": "2023-02-07T21:52:26.335521",
     "exception": false,
     "start_time": "2023-02-07T21:50:38.507325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/rsna-2022-whl/pydicom-2.3.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/rsna-2022-whl/pylibjpeg-1.4.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/rsna-2022-whl/python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg==1.4.0) (1.21.6)\r\n",
      "pydicom is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Installing collected packages: python-gdcm, pylibjpeg\r\n",
      "Successfully installed pylibjpeg-1.4.0 python-gdcm-3.0.15\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/rsna-2022-whl/torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Processing /kaggle/input/rsna-2022-whl/torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.12.1) (4.1.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.1) (2.28.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.1) (1.21.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.1) (9.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1) (1.26.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1) (2022.9.24)\r\n",
      "Installing collected packages: torch, torchvision\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0\r\n",
      "    Uninstalling torch-1.11.0:\r\n",
      "      Successfully uninstalled torch-1.11.0\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.12.0\r\n",
      "    Uninstalling torchvision-0.12.0:\r\n",
      "      Successfully uninstalled torchvision-0.12.0\r\n",
      "Successfully installed torch-1.12.1 torchvision-0.13.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# This is a dependency that is needed for reading DICOM images\n",
    "\n",
    "try:\n",
    "    import pylibjpeg\n",
    "except:\n",
    "    !rm -rf /root/.cache/torch/hub/checkpoints/\n",
    "    !mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "    !pip install /kaggle/input/rsna-2022-whl/{pydicom-2.3.0-py3-none-any.whl,pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}\n",
    "    !pip install /kaggle/input/rsna-2022-whl/{torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl,torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl}\n",
    "\n",
    "# copying the pretrained weights\n",
    "\n",
    "if not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n",
    "        os.makedirs('/root/.cache/torch/hub/checkpoints/')\n",
    "!cp '/kaggle/input/pretrained-model-weights-for-fastai/resnet18-f37072fd.pth' '/root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth'\n",
    "!cp '/kaggle/input/pretrained-model-weights-for-fastai/tf_efficientnetv2_s-eb54923e.pth' '/root/.cache/torch/hub/checkpoints/tf_efficientnetv2_s-eb54923e.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b256694a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:52:26.350276Z",
     "iopub.status.busy": "2023-02-07T21:52:26.349342Z",
     "iopub.status.idle": "2023-02-07T21:54:42.922073Z",
     "shell.execute_reply": "2023-02-07T21:54:42.921081Z"
    },
    "papermill": {
     "duration": 136.588576,
     "end_time": "2023-02-07T21:54:42.930536",
     "exception": false,
     "start_time": "2023-02-07T21:52:26.341960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 1.94 s, total: 1min 26s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds, labels = [], []\n",
    "\n",
    "SPLIT = 0 # our learner needs this to construct its dataloaders...\n",
    "learn = get_learner('tf_efficientnetv2_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbeeb92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:54:42.944644Z",
     "iopub.status.busy": "2023-02-07T21:54:42.944315Z",
     "iopub.status.idle": "2023-02-07T21:54:42.948928Z",
     "shell.execute_reply": "2023-02-07T21:54:42.947921Z"
    },
    "papermill": {
     "duration": 0.014084,
     "end_time": "2023-02-07T21:54:42.951121",
     "exception": false,
     "start_time": "2023-02-07T21:54:42.937037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instead of training, to conserve pipeline time, I am uploading models trained locally\n",
    "# uncomment the lines below for training\n",
    "  \n",
    "#for SPLIT in range(NUM_SPLITS):\n",
    "#     learn = get_learner('tf_efficientnetv2_s')\n",
    "#     learn.unfreeze()\n",
    "#     learn.fit_one_cycle(NUM_EPOCHS, 1e-4, pct_start=0.1)\n",
    "#     learn.save(f'{MODEL_PATH}/{SPLIT}')\n",
    "        \n",
    "#     output = learn.get_preds()\n",
    "#     preds.append(output[0])\n",
    "#     labels.append(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6ec01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:54:42.964625Z",
     "iopub.status.busy": "2023-02-07T21:54:42.964289Z",
     "iopub.status.idle": "2023-02-07T21:54:42.968542Z",
     "shell.execute_reply": "2023-02-07T21:54:42.967502Z"
    },
    "papermill": {
     "duration": 0.013596,
     "end_time": "2023-02-07T21:54:42.970800",
     "exception": false,
     "start_time": "2023-02-07T21:54:42.957204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# threshold = optimize_preds(torch.cat(preds), torch.cat(labels), return_thresh=True, print_results=True)\n",
    "threshold = 0.402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad31b02",
   "metadata": {
    "papermill": {
     "duration": 0.005912,
     "end_time": "2023-02-07T21:54:42.982772",
     "exception": false,
     "start_time": "2023-02-07T21:54:42.976860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicting on test<a id=\"section-two\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad8c298",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-02-07T21:54:42.996249Z",
     "iopub.status.busy": "2023-02-07T21:54:42.995928Z",
     "iopub.status.idle": "2023-02-07T21:54:47.910067Z",
     "shell.execute_reply": "2023-02-07T21:54:47.908700Z"
    },
    "papermill": {
     "duration": 4.924118,
     "end_time": "2023-02-07T21:54:47.912906",
     "exception": false,
     "start_time": "2023-02-07T21:54:42.988788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pydicom\n",
    "# from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import dicomsdl\n",
    "    \n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "import cv2\n",
    "\n",
    "!rm -rf test_resized_{RESIZE_TO[0]}\n",
    "\n",
    "def dicom_file_to_ary(path):\n",
    "    dcm_file = dicomsdl.open(str(path))\n",
    "    data = dcm_file.pixelData()\n",
    "\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "    if dcm_file.getPixelDataInfo()['PhotometricInterpretation'] == \"MONOCHROME1\":\n",
    "        data = 1 - data\n",
    "\n",
    "    data = cv2.resize(data, RESIZE_TO)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "directories = list(Path(TEST_DICOM_DIR).iterdir())\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    parent_directory = str(directory_path).split('/')[-1]\n",
    "    !mkdir -p test_resized_{RESIZE_TO[0]}/{parent_directory}\n",
    "    for image_path in directory_path.iterdir():\n",
    "        processed_ary = dicom_file_to_ary(image_path)\n",
    "        cv2.imwrite(\n",
    "            f'test_resized_{RESIZE_TO[0]}/{parent_directory}/{image_path.stem}.png',\n",
    "            processed_ary\n",
    "        )\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as p:\n",
    "    p.map(process_directory, directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa45a8c",
   "metadata": {
    "papermill": {
     "duration": 0.005982,
     "end_time": "2023-02-07T21:54:47.926142",
     "exception": false,
     "start_time": "2023-02-07T21:54:47.920160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Cropping images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f7bc4",
   "metadata": {
    "papermill": {
     "duration": 0.006295,
     "end_time": "2023-02-07T21:54:47.938533",
     "exception": false,
     "start_time": "2023-02-07T21:54:47.932238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c097072a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:54:47.952680Z",
     "iopub.status.busy": "2023-02-07T21:54:47.951733Z",
     "iopub.status.idle": "2023-02-07T21:55:07.437004Z",
     "shell.execute_reply": "2023-02-07T21:55:07.435665Z"
    },
    "papermill": {
     "duration": 19.495285,
     "end_time": "2023-02-07T21:55:07.439808",
     "exception": false,
     "start_time": "2023-02-07T21:54:47.944523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.69 s, sys: 1.76 s, total: 5.45 s\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds_all = []\n",
    "\n",
    "test_dl = learn.dls.test_dl(get_image_files(f'test_resized_{RESIZE_TO[0]}'))\n",
    "for SPLIT in range(NUM_SPLITS):\n",
    "    learn.load(f'{MODEL_PATH}/{SPLIT}')\n",
    "    preds, _ = learn.get_preds(dl=test_dl)\n",
    "    preds_all.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86f747c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:55:07.455986Z",
     "iopub.status.busy": "2023-02-07T21:55:07.455673Z",
     "iopub.status.idle": "2023-02-07T21:55:07.463344Z",
     "shell.execute_reply": "2023-02-07T21:55:07.462467Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.017975,
     "end_time": "2023-02-07T21:55:07.465247",
     "exception": false,
     "start_time": "2023-02-07T21:55:07.447272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = torch.zeros_like(preds_all[0])\n",
    "for pred in preds_all:\n",
    "    preds += pred\n",
    "\n",
    "preds /= NUM_SPLITS\n",
    "\n",
    "\n",
    "preds = optimize_preds(preds, thresh=threshold)\n",
    "image_ids = [path.stem for path in test_dl.items]\n",
    "\n",
    "image_id2pred = defaultdict(lambda: 0)\n",
    "for image_id, pred in zip(image_ids, preds[:, 1]):\n",
    "    image_id2pred[int(image_id)] = pred.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1403ee54",
   "metadata": {
    "papermill": {
     "duration": 0.006637,
     "end_time": "2023-02-07T21:55:07.478660",
     "exception": false,
     "start_time": "2023-02-07T21:55:07.472023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"section-three\"></a>\n",
    "# Making a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fee33e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:55:07.493566Z",
     "iopub.status.busy": "2023-02-07T21:55:07.493255Z",
     "iopub.status.idle": "2023-02-07T21:55:07.524111Z",
     "shell.execute_reply": "2023-02-07T21:55:07.523066Z"
    },
    "papermill": {
     "duration": 0.040951,
     "end_time": "2023-02-07T21:55:07.526441",
     "exception": false,
     "start_time": "2023-02-07T21:55:07.485490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10008_L</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10008_R</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction_id  cancer\n",
       "0       10008_L     0.0\n",
       "1       10008_R     0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n",
    "\n",
    "prediction_ids = []\n",
    "preds = []\n",
    "\n",
    "for _, row in test_csv.iterrows():\n",
    "    prediction_ids.append(row.prediction_id)\n",
    "    preds.append(image_id2pred[row.image_id])\n",
    "\n",
    "submission = pd.DataFrame(data={'prediction_id': prediction_ids, 'cancer': preds}).groupby('prediction_id').max().reset_index()\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d171f680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T21:55:07.541642Z",
     "iopub.status.busy": "2023-02-07T21:55:07.541379Z",
     "iopub.status.idle": "2023-02-07T21:55:07.549119Z",
     "shell.execute_reply": "2023-02-07T21:55:07.548325Z"
    },
    "papermill": {
     "duration": 0.017383,
     "end_time": "2023-02-07T21:55:07.551103",
     "exception": false,
     "start_time": "2023-02-07T21:55:07.533720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 357.37616,
   "end_time": "2023-02-07T21:55:10.043092",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-07T21:49:12.666932",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
